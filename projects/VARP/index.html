<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="VARP: RL from VLM Feedback with Agent Regularized Preferences">
  <meta name="author" content="Anukriti Singh, Amisha Bhaskar, et al.">
  <link rel="icon" href="../favicon.ico">
  <title>VARP | RAAS Lab</title>

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
  <link href="css/style.css" rel="stylesheet">

  <style>
    .justified-text {
      text-align: justify;
    }
    .prompt-box {
      background-color: #f8f9fa;
      border-left: 5px solid #007bff;
      padding: 15px;
      margin: 20px 0;
      border-radius: 8px;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    }
    .prompt-title {
      font-weight: bold;
      color: #007bff;
    }
  </style>
</head>

<body>
  <!-- Hero Section -->
  <header class="jumbotron text-center py-5 bg-light">
    <div class="container">
      <h1 class="display-4">VARP:</h1>
      <h3>Reinforcement Learning from VLM Feedback with Agent Regularized Preferences</h3>
    </div>
  </header>

  <!-- Abstract Section -->
  <section id="abstract" class="container py-5">
    <h2 class="text-center">Abstract</h2>
    <p class="justified-text">
      Designing reward functions for continuous-control robotics often leads to subtle misalignments or reward hacking, especially in complex tasks. 
      Preference-based RL mitigates some of these pitfalls by learning rewards from comparative feedback rather than hand-crafted signals, yet scaling human annotations remains challenging. 
      Recent work uses VisionLanguage Models (VLMs) to automate preference labeling, but a single final-state image generally fails to capture the agent’s full motion. 
      In this paper, we present a two-part solution that both improves feedback accuracy and better aligns reward learning with the agent’s policy. 
      First, we overlay trajectory sketches on final observations to reveal the path taken, allowing VLMs to provide more reliable preferences—improving preference accuracy by approximately 15–20% in metaworld tasks. 
      Second, we regularize reward learning by incorporating the agent’s performance, ensuring that the reward model is optimized based on data generated by the current policy; 
      this addition boosts episode returns by 20–30% in locomotion tasks. 
      Empirical studies on metaworld demonstrate that our method achieves, for instance, around 70-80% success rate in all tasks, compared to below 50% for standard approaches. 
      These results underscore the efficacy of combining richer visual representations with agent-aware reward regularization.
    </p>
  </section>

  <!-- Video Section -->
  <section id="video" class="container text-center py-5">
    <h2>Presentation Video</h2>
    <div class="ratio ratio-16x9 mx-auto" style="max-width: 800px;">
      <video class="embed-responsive-item" controls>
        <source src="assets/varp_video.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </section>

  <!-- Task GIFs Section -->
  <section id="tasks" class="container text-center py-5">
    <h2>Task Visualizations</h2>
    <div class="row justify-content-center">
      <div class="col-md-4">
        <img src="assets/gifs/drawer_open.gif" class="img-fluid rounded shadow" alt="Drawer Open">
        <p>Drawer Open</p>
      </div>
      <div class="col-md-4">
        <img src="assets/gifs/soccer.gif" class="img-fluid rounded shadow" alt="Soccer">
        <p>Soccer</p>
      </div>
      <div class="col-md-4">
        <img src="assets/gifs/sweep_into.gif" class="img-fluid rounded shadow" alt="Sweep Into">
        <p>Sweep Into</p>
      </div>
    </div>
  </section>

  <!-- Prompt Template Section -->
<!-- Prompt Template Section -->
<section id="prompt" class="container text-center py-5">
  <h2 class="text-center">Prompt Template</h2>

  <div class="prompt-box text-start">
    <p class="prompt-title">Analysis Template</p>
    <p class="prompt-content">Describe the two images given to you, which includes final frames with a sketch of trajectory for the goal <strong>[task description]</strong> from the MetaWorld simulation environment. 
      The sketch image on the final frame features a simple, 3D-rendered scene. Notably, a trajectory is sketched and represented by a thin, yellow color. The trajectory’s color uses yellow to indicate temporal progress. 
      Brighter yellow signifies the beginning of the trajectory, while darker brown represents the end, visualizing a temporal progression.</p>
    <ul class="prompt-list">
      <li>How is the sketch shown in Image 1?</li>
      <li>How is the sketch shown in Image 2?</li>
      <li>Is there any difference between Image 1 and Image 2 in terms of achieving the goal?</li>
    </ul>
  </div>

  <div class="prompt-box text-start">
    <p class="prompt-title">Labeling Template</p>
    <p class="prompt-content">Based on the text below, answer the following questions:</p>
    <p class="prompt-content">The goal is <strong>[task description]</strong>. The most efficient robot arm movement would involve pulling the handle straight back along the linear path of the drawer’s opening direction with a steady and controlled force.</p>
    <ul class="prompt-list">
      <li>How well is the goal achieved in Image 1, and how is the sketch trajectory?</li>
      <li>How well is the goal achieved in Image 2, and how is the sketch trajectory?</li>
      <li>Is there any difference between Image 1 and Image 2 in terms of achieving the goal?</li>
    </ul>
    
    <p class="prompt-content">Is the goal better achieved in Image 1 or Image 2?</p>
    <ul class="prompt-list">
      <li>Reply <strong>0</strong> if the goal is better achieved in Image 1.</li>
      <li>Reply <strong>1</strong> if the goal is better achieved in Image 2.</li>
      <li>Reply <strong>-1</strong> if the text is unsure or if there is no difference.</li>
    </ul>
  </div>
</section>


  <!-- Footer -->
  <footer class="bg-dark text-white text-center py-3">
    <p>&copy; 2025 VARP Project | RAAS Lab</p>
  </footer>

  <!-- Bootstrap Scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>


lets make this a little pretty, not too fancy just first make the template part better 
